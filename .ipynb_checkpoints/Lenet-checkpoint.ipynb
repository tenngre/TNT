{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# imports used to build the deep learning model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition of a LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lenet(width, height, depth, classes, weightsPath=None):\n",
    "    # Initialize the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # The first set of CONV => RELU => POOL layers\n",
    "    # If you need a traditional lenet, you can change the to padding=\"vailed\"\n",
    "    model.add(Conv2D(20, (5, 5), padding=\"same\",\n",
    "                     input_shape=(height, width, depth), name='CONV1'))\n",
    "    model.add(Activation(\"relu\", name='relu1'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='Pooling1'))\n",
    "\n",
    "    # The second set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(50, (5, 5), padding=\"same\", name='CONV2'))\n",
    "    model.add(Activation(\"relu\", name='relu2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='Pooling2'))\n",
    "    model.add(Dropout(0.025))\n",
    "\n",
    "    # The set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation(\"relu\", name='relu3'))\n",
    "    model.add(Dropout(0.025))\n",
    "    \n",
    "    # The softmax classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"softmax\", name='softmax'))\n",
    "\n",
    "    # If a weights path is supplied, then load the weights\n",
    "    if weightsPath is not None:\n",
    "        model.load_weights(weightsPath)\n",
    "\n",
    "    # Return the constructed network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing The MNIST Dataset\n",
    "\n",
    "We prepare two types of input dataset. The first one is ternary type, the second one is normal type. <br>\n",
    "1. Ternary input: is that every pixel is converted to -1, 0 or 1. <br>\n",
    "2. Normal input: is that every pixel is in range 0~255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading the MNIST Normal dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Loading the MNIST Normal dataset...\")\n",
    "(trainData, trainLabels), (testData, testLabels) = mnist.load_data()\n",
    "trainData = trainData[:, :, :, np.newaxis]\n",
    "testData = testData[:, :, :, np.newaxis]\n",
    "# Rescale the data from values between [0 - 255] to [0 - 1.0]\n",
    "trainData = trainData / 255.0\n",
    "testData = testData / 255.0\n",
    "trainLabels = np_utils.to_categorical(trainLabels, 10)\n",
    "testLabels = np_utils.to_categorical(testLabels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initializing The LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Building and compiling the LeNet model...\n",
      "WARNING:tensorflow:From /Users/Tenngre/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/Tenngre/anaconda/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "CONV1 (Conv2D)               (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 28, 28, 20)        0         \n",
      "_________________________________________________________________\n",
      "Pooling1 (MaxPooling2D)      (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "CONV2 (Conv2D)               (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "Pooling2 (MaxPooling2D)      (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and Compile the model\n",
    "print(\"[INFO] Building and compiling the LeNet model...\")\n",
    "model = build_lenet(width=28, height=28, depth=1, classes=10)\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Lenet by Ternary Input or Normal Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Normal input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Normal Input to train a model...\n",
      "WARNING:tensorflow:From /Users/Tenngre/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      " 3072/60000 [>.............................] - ETA: 2:25 - loss: 2.2705 - acc: 0.2295"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Using Normal Input to train a model...\")\n",
    "history = model.fit(trainData,\n",
    "                    trainLabels,\n",
    "                    batch_size=128,\n",
    "                    epochs=3,\n",
    "                    validation_data=(testData, testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Ternar Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] Using Ternary Input to train a model...\")\n",
    "history = model.fit(ternary_train,\n",
    "                    trainLabels,\n",
    "                    batch_size=128,\n",
    "                    epochs=3,\n",
    "                    validation_data=(ternary_test, testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualizing The Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_training_history(history):\n",
    "    plt.figure(1)\n",
    "\n",
    "    # summarize history for accuracy\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    # summarize history for loss\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Evaluation\n",
    "Use **ternary_test**, if you use ternary input. Otherwise, **testData**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ternary_test: for ternary input\n",
    "# testData: for normal input\n",
    "(loss, accuracy) = model.evaluate(\n",
    "        ternary_test, testLabels, batch_size=128, verbose=1)\n",
    "print(\"[INFO] accuracy of floating model: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Visualize the training history\n",
    "graph_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/LeNet_models_padding_dropout.model', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test MNIST Dataset\n",
    "Randomly select one image from test dataset to predict the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.choice(np.arange(0, len(testLabels)), size=(10,)):\n",
    "    # Use the model to classify the digit\n",
    "    probs = model.predict(testData[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "\n",
    "    # Convert the digit data to a color image\n",
    "    image = (testData[i] * 255).astype(\"uint8\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # The images are in 28x28 size. Much too small to see properly\n",
    "    # So, we resize them to 280x280 for viewing\n",
    "    image = cv2.resize(image, (280, 280), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Add the predicted value on to the image\n",
    "    cv2.putText(image, str(prediction[0]), (20, 40),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, 1.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Show the image and prediction\n",
    "    print(\"[INFO] Predicted: {}, Actual: {}\".format(\n",
    "        prediction[0], np.argmax(testLabels[i])))\n",
    "    cv2.imshow(\"Digit\", image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
